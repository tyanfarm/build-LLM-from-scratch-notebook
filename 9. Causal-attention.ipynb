{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e2951b4",
   "metadata": {},
   "source": [
    "## Causal Attention V1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed08c29",
   "metadata": {},
   "source": [
    "- Sử dụng `SelfAttention_v2` được implement ở phần trước"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "483b1c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch \n",
    "\n",
    "class SelfAttention_v2(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out, qkv_bias=False):\n",
    "        super().__init__()     # Khởi tạo lớp cha nn.Module\n",
    "        self.dim_out = dim_out  # Kích thước đầu ra\n",
    "        self.W_query = nn.Linear(dim_in, dim_out, bias=qkv_bias)  # Lớp Linear cho query\n",
    "        self.W_key = nn.Linear(dim_in, dim_out, bias=qkv_bias)    # Lớp Linear cho key\n",
    "        self.W_value = nn.Linear(dim_in, dim_out, bias=qkv_bias)  # Lớp Linear cho value\n",
    "\n",
    "    def forward(self, x):\n",
    "        queries = self.W_query(x)   # X . Wq \n",
    "        keys = self.W_key(x)         # X . Wk\n",
    "        values = self.W_value(x)     # X . Wv\n",
    "\n",
    "        attn_scores = queries @ keys.T      # Tính attention scores (omega)\n",
    "        attn_weights = torch.softmax(\n",
    "            attn_scores / keys.shape[-1]**0.5, dim=-1\n",
    "        )\n",
    "\n",
    "        context_vectors = attn_weights @ values  # Tính context vectors (z)\n",
    "\n",
    "        return context_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "018f2153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5337, -0.1051],\n",
      "        [-0.5323, -0.1080],\n",
      "        [-0.5323, -0.1079],\n",
      "        [-0.5297, -0.1076],\n",
      "        [-0.5311, -0.1066],\n",
      "        [-0.5299, -0.1081]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "inputs = torch.tensor(\n",
    "    [[0.43, 0.15, 0.89], # Your (x^1)\n",
    "    [0.55, 0.87, 0.66], # journey (x^2)\n",
    "    [0.57, 0.85, 0.64], # starts (x^3)\n",
    "    [0.22, 0.58, 0.33], # with (x^4)\n",
    "    [0.77, 0.25, 0.10], # one (x^5)\n",
    "    [0.05, 0.80, 0.55]] # step (x^6)\n",
    ")\n",
    "self_attention_v2 = SelfAttention_v2(dim_in=3, dim_out=2, qkv_bias=False)\n",
    "print(self_attention_v2(inputs))    # run forward with inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1249b718",
   "metadata": {},
   "source": [
    "- Sử dụng `causal attention mask`, bao gồm 3 bước như sau:\n",
    "\n",
    "    + 1. Áp dụng _softmax_.\n",
    "    + 2. _Mask_ bằng 0 với các weights phía trên đường chéo chính.\n",
    "    + 3. Normalize các hàng."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8c4daf",
   "metadata": {},
   "source": [
    "#### 1. Áp dụng softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25d276ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Scores:\n",
      "tensor([[0.3111, 0.3479, 0.3471, 0.1714, 0.2350, 0.1928],\n",
      "        [0.1655, 0.2602, 0.2576, 0.1445, 0.1384, 0.1790],\n",
      "        [0.1667, 0.2602, 0.2577, 0.1443, 0.1391, 0.1784],\n",
      "        [0.0510, 0.1080, 0.1064, 0.0643, 0.0476, 0.0835],\n",
      "        [0.1415, 0.1875, 0.1863, 0.0987, 0.1121, 0.1174],\n",
      "        [0.0476, 0.1192, 0.1171, 0.0731, 0.0477, 0.0966]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "\n",
      "Attention Weights:\n",
      "tensor([[0.1717, 0.1762, 0.1761, 0.1555, 0.1627, 0.1579],\n",
      "        [0.1636, 0.1749, 0.1746, 0.1612, 0.1605, 0.1652],\n",
      "        [0.1637, 0.1749, 0.1746, 0.1611, 0.1606, 0.1651],\n",
      "        [0.1636, 0.1704, 0.1702, 0.1652, 0.1632, 0.1674],\n",
      "        [0.1667, 0.1722, 0.1721, 0.1618, 0.1633, 0.1639],\n",
      "        [0.1624, 0.1709, 0.1706, 0.1654, 0.1625, 0.1682]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "queries = self_attention_v2.W_query(inputs)\n",
    "keys = self_attention_v2.W_key(inputs)\n",
    "attention_scores = queries @ keys.T\n",
    "print(\"Attention Scores:\")\n",
    "print(attention_scores)  # print attention scores   \n",
    "attention_weights = torch.softmax(\n",
    "    attention_scores / keys.shape[-1]**0.5, dim=-1\n",
    ")\n",
    "print(\"\\nAttention Weights:\")\n",
    "print(attention_weights)  # print attention weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cb59eb",
   "metadata": {},
   "source": [
    "#### 2. _Mask_ với các weights phía trên đường chéo chính.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c94e91",
   "metadata": {},
   "source": [
    "- Sử dụng `.tril()` của Pytorch cho mask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84cde430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "context_length = attention_scores.shape[0]  # length of the input text\n",
    "mask_simple = torch.tril(torch.ones((context_length, context_length)))  # tril = Triangle Lower\n",
    "print(mask_simple)  # print the simple mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07adefde",
   "metadata": {},
   "source": [
    "- Áp dụng _mask_ này cho _attention weights_ bằng cách sử dụng `element-wise product`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "115c598f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1717, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1636, 0.1749, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1637, 0.1749, 0.1746, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1636, 0.1704, 0.1702, 0.1652, 0.0000, 0.0000],\n",
      "        [0.1667, 0.1722, 0.1721, 0.1618, 0.1633, 0.0000],\n",
      "        [0.1624, 0.1709, 0.1706, 0.1654, 0.1625, 0.1682]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "masked_simple = attention_weights * mask_simple\n",
    "print(masked_simple)  # print the masked attention weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e9c5dd",
   "metadata": {},
   "source": [
    "#### 3. Normalize các hàng.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b799de66",
   "metadata": {},
   "source": [
    "- Sau khi áp dụng _mask_, ta cần thêm bước _normalize_ theo từng hàng để tổng từng hàng vẫn bằng 1 như cũ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0857abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.4833, 0.5167, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3190, 0.3408, 0.3402, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2445, 0.2545, 0.2542, 0.2468, 0.0000, 0.0000],\n",
      "        [0.1994, 0.2060, 0.2058, 0.1935, 0.1953, 0.0000],\n",
      "        [0.1624, 0.1709, 0.1706, 0.1654, 0.1625, 0.1682]],\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "row_sums = masked_simple.sum(dim=-1, keepdim=True)\n",
    "masked_simple_norm = masked_simple / row_sums\n",
    "print(masked_simple_norm)  # print the normalized masked attention weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c066bb31",
   "metadata": {},
   "source": [
    "- Khi ta áp dụng _mask_ & _renormalize_ lại _attention weights_, thoạt nhìn thì có vẻ các _future token_ vẫn đóng góp vào _token hiện tại_ vì phép tính _softmax_ tính toán trên từng hàng, nhưng thực tế không như vậy. \n",
    "\n",
    "- Vì khi ta _renormalize_ lại sau khi _mask_, bản chất ta đang tính _softmax_ trên `1 tập nhỏ hơn`, với các token bị loại là các `masked token`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5873661a",
   "metadata": {},
   "source": [
    "## Causal Attention V2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d482be2",
   "metadata": {},
   "source": [
    "- Ở version 2 này ta chỉ cần _mask_ với 2 bước. Thay vì _mask_ các `future token` bằng 0, ta sẽ _mask_ bằng $-\\infty$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0317fdaf",
   "metadata": {},
   "source": [
    "- Sử dụng `causal attention mask v2`, bao gồm 2 bước như sau:\n",
    "\n",
    "    + 1. _Mask_ $-\\infty$ với các scores phía trên đường chéo chính.\n",
    "    + 2. Áp dụng _softmax_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dde45b",
   "metadata": {},
   "source": [
    "#### 1. _Mask_ $-\\infty$ với các scores phía trên đường chéo chính.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b82f442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triangle Upper Mask:\n",
      "tensor([[0., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0.]])\n",
      "\n",
      "Masked Attention Scores:\n",
      "tensor([[0.3111,   -inf,   -inf,   -inf,   -inf,   -inf],\n",
      "        [0.1655, 0.2602,   -inf,   -inf,   -inf,   -inf],\n",
      "        [0.1667, 0.2602, 0.2577,   -inf,   -inf,   -inf],\n",
      "        [0.0510, 0.1080, 0.1064, 0.0643,   -inf,   -inf],\n",
      "        [0.1415, 0.1875, 0.1863, 0.0987, 0.1121,   -inf],\n",
      "        [0.0476, 0.1192, 0.1171, 0.0731, 0.0477, 0.0966]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mask = torch.triu(torch.ones(context_length, context_length), diagonal=1)   # triu = Triangle Upper\n",
    "print(\"Triangle Upper Mask:\")\n",
    "print(mask)  # print the upper triangular mask\n",
    "\n",
    "print(\"\\nMasked Attention Scores:\")\n",
    "masked = attention_scores.masked_fill(mask.bool(), -torch.inf)\n",
    "print(masked)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af93ab61",
   "metadata": {},
   "source": [
    "#### 2. Áp dụng softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "540fa5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.4833, 0.5167, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3190, 0.3408, 0.3402, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2445, 0.2545, 0.2542, 0.2468, 0.0000, 0.0000],\n",
      "        [0.1994, 0.2060, 0.2058, 0.1935, 0.1953, 0.0000],\n",
      "        [0.1624, 0.1709, 0.1706, 0.1654, 0.1625, 0.1682]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "attention_weights = torch.softmax(\n",
    "    masked / keys.shape[-1]**0.5, dim=-1\n",
    ")\n",
    "\n",
    "print(attention_weights)  # print the masked attention weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "989f506e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4519,  0.2216],\n",
       "        [-0.5874,  0.0058],\n",
       "        [-0.6300, -0.0632],\n",
       "        [-0.5675, -0.0843],\n",
       "        [-0.5526, -0.0981],\n",
       "        [-0.5299, -0.1081]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vectors = attention_weights @ self_attention_v2.W_value(inputs)\n",
    "context_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c10f65b",
   "metadata": {},
   "source": [
    "## Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06f9c309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Tensor:\n",
      "tensor([[1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1.]])\n",
      "\n",
      "After Dropout:\n",
      "tensor([[2., 2., 0., 2., 2., 0.],\n",
      "        [0., 0., 0., 2., 0., 2.],\n",
      "        [2., 2., 2., 2., 0., 2.],\n",
      "        [0., 2., 2., 0., 0., 2.],\n",
      "        [0., 2., 0., 2., 0., 2.],\n",
      "        [0., 2., 2., 2., 2., 0.]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "dropout = torch.nn.Dropout(0.5) \n",
    "example = torch.ones(6, 6)\n",
    "print(\"Example Tensor:\")\n",
    "print(example)  # print the example tensor\n",
    "print(\"\\nAfter Dropout:\")\n",
    "print(dropout(example))  # apply dropout to the example tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1637b4c",
   "metadata": {},
   "source": [
    "- Khi áp dụng `dropout` lên 1 ma trận với tỉ lệ 50%, một nửa số phần tử sẽ được đặt về 0. Để bù cho sự giảm bớt các phần tử, giá trị của các phần tử còn lại được tăng lên (scale up) theo hệ số _1/0.5 = 2_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25acd7cf",
   "metadata": {},
   "source": [
    "## Compact Causal Attention Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4212ce4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.shape: torch.Size([2, 6, 3]) -- (batch_size, context_length / num_tokens, dim_in)\n",
      "tensor([[[0.4300, 0.1500, 0.8900],\n",
      "         [0.5500, 0.8700, 0.6600],\n",
      "         [0.5700, 0.8500, 0.6400],\n",
      "         [0.2200, 0.5800, 0.3300],\n",
      "         [0.7700, 0.2500, 0.1000],\n",
      "         [0.0500, 0.8000, 0.5500]],\n",
      "\n",
      "        [[0.4300, 0.1500, 0.8900],\n",
      "         [0.5500, 0.8700, 0.6600],\n",
      "         [0.5700, 0.8500, 0.6400],\n",
      "         [0.2200, 0.5800, 0.3300],\n",
      "         [0.7700, 0.2500, 0.1000],\n",
      "         [0.0500, 0.8000, 0.5500]]])\n"
     ]
    }
   ],
   "source": [
    "batch = torch.stack((inputs, inputs), dim=0)    # dim = 0 -- index dim of combining tensors\n",
    "print(f\"batch.shape: {batch.shape} -- (batch_size, context_length / num_tokens, dim_in)\")\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2189c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalAttention(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out, context_length, dropout, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.dim_out = dim_out\n",
    "        self.W_query = nn.Linear(dim_in, dim_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(dim_in, dim_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(dim_in, dim_out, bias=qkv_bias)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(   # Đăng ký một tensor không phải là tham số của mô hình\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, dim_in = x.shape\n",
    "\n",
    "        # 3 Q,K,V có shape (batch_size, context_length, dim_out)\n",
    "        keys = self.W_key(x)    \n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        # keys.transpose(1, 2) đổi shape từ (B, T, D) thành (B, D, T)\n",
    "        attention_scores = queries @ keys.transpose(1, 2)  \n",
    "        print(f\"Batch Attention Scores:\")\n",
    "        print(attention_scores)\n",
    "        # [:num_tokens, :num_tokens] -- Slicing mask để phù hợp với số token hiện tại\n",
    "        attention_scores.masked_fill_(\n",
    "            self.mask.bool()[:num_tokens, :num_tokens], -torch.inf  # Dùng được từ register_buffer \n",
    "        )\n",
    "        attention_weights = torch.softmax(\n",
    "            attention_scores / keys.shape[-1]**0.5, dim=-1\n",
    "        )\n",
    "        attention_weights = self.dropout(attention_weights)\n",
    "\n",
    "        context_vectors = attention_weights @ values\n",
    "\n",
    "        return context_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9efe0f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Attention Scores:\n",
      "tensor([[[0.3111, 0.3479, 0.3471, 0.1714, 0.2350, 0.1928],\n",
      "         [0.1655, 0.2602, 0.2576, 0.1445, 0.1384, 0.1790],\n",
      "         [0.1667, 0.2602, 0.2577, 0.1443, 0.1391, 0.1784],\n",
      "         [0.0510, 0.1080, 0.1064, 0.0643, 0.0476, 0.0835],\n",
      "         [0.1415, 0.1875, 0.1863, 0.0987, 0.1121, 0.1174],\n",
      "         [0.0476, 0.1192, 0.1171, 0.0731, 0.0477, 0.0966]],\n",
      "\n",
      "        [[0.3111, 0.3479, 0.3471, 0.1714, 0.2350, 0.1928],\n",
      "         [0.1655, 0.2602, 0.2576, 0.1445, 0.1384, 0.1790],\n",
      "         [0.1667, 0.2602, 0.2577, 0.1443, 0.1391, 0.1784],\n",
      "         [0.0510, 0.1080, 0.1064, 0.0643, 0.0476, 0.0835],\n",
      "         [0.1415, 0.1875, 0.1863, 0.0987, 0.1121, 0.1174],\n",
      "         [0.0476, 0.1192, 0.1171, 0.0731, 0.0477, 0.0966]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "\n",
      "Batch Context Vectors:\n",
      "tensor([[[-0.4519,  0.2216],\n",
      "         [-0.5874,  0.0058],\n",
      "         [-0.6300, -0.0632],\n",
      "         [-0.5675, -0.0843],\n",
      "         [-0.5526, -0.0981],\n",
      "         [-0.5299, -0.1081]],\n",
      "\n",
      "        [[-0.4519,  0.2216],\n",
      "         [-0.5874,  0.0058],\n",
      "         [-0.6300, -0.0632],\n",
      "         [-0.5675, -0.0843],\n",
      "         [-0.5526, -0.0981],\n",
      "         [-0.5299, -0.1081]]], grad_fn=<UnsafeViewBackward0>)\n",
      "\n",
      "context_vectors.shape: torch.Size([2, 6, 2])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "context_length = batch.shape[1]\n",
    "\n",
    "causal_attention = CausalAttention(dim_in=3, dim_out=2, context_length=context_length, dropout=0.0)\n",
    "context_vectors = causal_attention(batch)\n",
    "print(\"\\nBatch Context Vectors:\")\n",
    "print(context_vectors)\n",
    "print(\"\\ncontext_vectors.shape:\", context_vectors.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
